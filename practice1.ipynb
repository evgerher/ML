{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we will implement linear regression from scratch\n",
    "## The task is to compare results of linear, polynomial and interactive regressions\n",
    "### In addition we will implement different validation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data_pd(df):\n",
    "    #return df.reindex(np.random.permutation(df.index))\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "def shuffle_data_np(dataset):\n",
    "    np.random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def example():\n",
    "    df = pd.DataFrame(np.random.random((6, 2)), columns=['a', 'b'])\n",
    "    num = np.random.random((6, 2))\n",
    "    print(df)\n",
    "    print(shuffle_data_pd(df))\n",
    "\n",
    "    print(num)\n",
    "\n",
    "    print(shuffle_data_np(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv_split_hands(dataset, k):\n",
    "    N = len(dataset)\n",
    "    #shuffle\n",
    "    indexes = np.arange(0, N)\n",
    "    indexes = shuffle_data_np(indexes)\n",
    "    \n",
    "    # splitting\n",
    "    \n",
    "    trains = []\n",
    "    tests = []\n",
    "    \n",
    "    fraction = 1. / k\n",
    "    \n",
    "    for i in range(k):\n",
    "        trains.append([])\n",
    "        tests.append([])\n",
    "        \n",
    "        bottom = (int)(fraction * i * N)\n",
    "        top = (int)(fraction * (i+1) * N)\n",
    "        if top > N:\n",
    "            top = N\n",
    "\n",
    "        tests[i] = indexes[bottom:top]\n",
    "        \n",
    "        train1 = indexes[0:bottom]\n",
    "        train2 = indexes[top:N]\n",
    "        trains[i] = np.concatenate((train1, train2))\n",
    "        \n",
    "    return trains, tests\n",
    "    \n",
    "def k_fold_cv_tools(dataset, k):\n",
    "    pass\n",
    "    \n",
    "def cv_example():\n",
    "    df = pd.DataFrame(np.random.random((18, 2)), columns=['a', 'b'])\n",
    "    print(df)\n",
    "    train_indexes, test_indexes = k_fold_cv_split_hands(df, 3)\n",
    "    print(train_indexes)\n",
    "    print(test_indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(dataset, k, method,  method_type, pred_cols):\n",
    "    def get_error(predicted, actual, method_type):\n",
    "        if method_type in 'regression': #MSE\n",
    "            summ = 0\n",
    "            actual = actual['mpg'].tolist()\n",
    "            for i in range(len(predicted)):\n",
    "                summ += (predicted[i] - actual[i]) ** 2\n",
    "            return summ / len(predicted)\n",
    "        else: # Classification error\n",
    "            counter = 0 # WORK WITH PANDAS DF\n",
    "            actual = actual['species'].tolist()\n",
    "            for i in range(len(predicted)):\n",
    "                counter += predicted[i] != actual[i]\n",
    "            return counter\n",
    "    \n",
    "    mses = []\n",
    "    X = dataset[pred_cols]\n",
    "    Y = dataset[[col for col in dataset.columns if col not in pred_cols]]\n",
    "    \n",
    "    trains, tests = k_fold_cv_split_hands(dataset, k)\n",
    "    for i in range(k):\n",
    "        train = trains[i]\n",
    "        test = tests[i]\n",
    "        train_X, train_Y = X.iloc[train, :], Y.iloc[train, :]\n",
    "        test_X, test_Y = X.iloc[test, :], Y.iloc[test, :]\n",
    "        method.fit(train_X, train_Y)\n",
    "        predict_Y = method.predict(test_X)\n",
    "        mse = get_error(predict_Y, test_Y, method_type)\n",
    "        mses.append(mse)\n",
    "    mmse = sum(mses) / len(mses)\n",
    "    return mses, mmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df, column):\n",
    "    average = 0.0\n",
    "    N = len(df)\n",
    "    indexes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row[column] == '?': # here also can be useful np.nan\n",
    "            indexes.append(index)\n",
    "        else:\n",
    "            average += (float)(row[column])\n",
    "    average = average * 1.0 / N\n",
    "    for ind in indexes:\n",
    "        df.at[ind, column] = average\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "398\n",
      "0      17.7\n",
      "1      13.0\n",
      "2      28.0\n",
      "3      24.2\n",
      "4      37.0\n",
      "5      13.0\n",
      "6      16.0\n",
      "7      18.0\n",
      "8      32.4\n",
      "9      26.0\n",
      "10     32.0\n",
      "11     18.0\n",
      "12     28.4\n",
      "13     37.3\n",
      "14     12.0\n",
      "15     24.5\n",
      "16     28.0\n",
      "17     14.0\n",
      "18     24.0\n",
      "19     18.2\n",
      "20     23.9\n",
      "21     20.0\n",
      "22     17.5\n",
      "23     18.0\n",
      "24     22.0\n",
      "25     36.1\n",
      "26     21.0\n",
      "27     33.8\n",
      "28     25.0\n",
      "29     21.0\n",
      "       ... \n",
      "248    15.0\n",
      "249    25.5\n",
      "250    16.0\n",
      "251    13.0\n",
      "252    13.0\n",
      "253    37.0\n",
      "254    14.0\n",
      "255    18.0\n",
      "256    14.0\n",
      "257    17.0\n",
      "258    23.0\n",
      "259    25.8\n",
      "260    18.0\n",
      "261    33.0\n",
      "262    38.0\n",
      "263    24.0\n",
      "264    20.5\n",
      "265    43.1\n",
      "266    29.9\n",
      "267    18.0\n",
      "268    21.5\n",
      "269    15.0\n",
      "270     9.0\n",
      "271    16.0\n",
      "272    22.0\n",
      "273    14.0\n",
      "274    25.0\n",
      "275    18.5\n",
      "276    15.5\n",
      "277    29.0\n",
      "Name: mpg, Length: 278, dtype: float64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "free variable 'i' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m#k_fold_cv(dataset, k, lin, 'regression', ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m \u001b[0mlin_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36mlin_example\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mlin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbettas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malfa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(self, x, y, alfa, stop, iter_limit, debug)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mderives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mderives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mderived_cost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mbettas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0malfa\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mderives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36mderived_cost_function\u001b[1;34m(self, x, y, bettas, index)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderived_cost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mderive_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# per one item\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-942f83af49fe>\u001b[0m in \u001b[0;36mderives_2\u001b[1;34m(x, y, bettas)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderives_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderives_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbettas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: free variable 'i' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "class MyRegression:\n",
    "    def __init__(self):\n",
    "        self.bettas = []\n",
    "        \n",
    "        \n",
    "    def gradient_descent(self, x, y, alfa, stop, iter_limit=100000, debug=False):\n",
    "        '''\n",
    "        x - matrix\n",
    "        y - vector\n",
    "        alfa - vector\n",
    "        stop - const\n",
    "        ---\n",
    "        bettas - vector\n",
    "        '''\n",
    "        \n",
    "        iterations = 0\n",
    "        N = len(x)\n",
    "        m = len(x.columns)\n",
    "        \n",
    "        bettas = [0] * (m + 1) # b0\n",
    "        bettas_best = [0] * (m + 1)\n",
    "        error = self.get_error(x, y, bettas, N)\n",
    "        error_old = error\n",
    "        \n",
    "        while (math.fabs(error) > stop and iterations < iter_limit):\n",
    "            #training\n",
    "            derives = [0] * m\n",
    "            for i in range(m):\n",
    "                derives = self.derived_cost_function(x, y, bettas, i)\n",
    "            for i in range(m):\n",
    "                bettas[i] -= alfa * derives[i]\n",
    "            error_old = error\n",
    "            error = self.get_error(x, y, bettas, N)\n",
    "            if error < error_old:\n",
    "                bettas_best = list(bettas)\n",
    "            if debug is True:\n",
    "                if iterations % 1000 == 0:\n",
    "                    print(bettas)\n",
    "                    print(\"Error {}\".format(error))\n",
    "            iteration += 1\n",
    "        return bettas_best\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.bettas = self.gradient_descent(x_train, y_train, alfa=0.95, stop=1e-2)\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        pass\n",
    "    \n",
    "    def cost_function(self, x_val, y_val, bettas):\n",
    "        pass\n",
    "    \n",
    "    def derived_cost_function(self, x, y, bettas, index):\n",
    "        pass\n",
    "    \n",
    "    def get_error(self, x, y, bettas, N):\n",
    "        err = 0\n",
    "        for i in range(N):\n",
    "            err += self.cost_function(x.iloc[i].tolist(), y[i], bettas)\n",
    "        return err / N\n",
    "\n",
    "class MyLinearRegression(MyRegression):\n",
    "    def __init__(self, cost_function, derive_functions=None):\n",
    "        super(MyLinearRegression, self).__init__()\n",
    "        self._cost_function = cost_function\n",
    "        self.derive_functions = derive_functions\n",
    "    \n",
    "    def derived_cost_function(self, x, y, bettas, index):\n",
    "        return self.derive_functions[index](x, y, bettas)\n",
    "\n",
    "    def cost_function(self, x, y, bettas): # per one item\n",
    "        return self._cost_function(x, y, bettas)\n",
    "    \n",
    "    def predict(x_test):\n",
    "        N = len(x_test)\n",
    "        results = [0] * N\n",
    "        for i in range(N):\n",
    "            results[i] = np.dot(([1] + x[i]), bettas)\n",
    "        return results\n",
    "\n",
    "def lin_example():\n",
    "    df = pd.read_csv('datasets/mpg.csv')\n",
    "    df = clean_dataset(df, 'horsepower')\n",
    "    df.drop(['name', 'model_year', 'origin'], axis=1, inplace=True)\n",
    "    df['horsepower'] = df.horsepower.astype(float)\n",
    "    \n",
    "    def cost_function(x, y, bettas):\n",
    "        val = (y - (np.dot(x, bettas[1:]) + bettas[0]))\n",
    "        return val ** 2\n",
    "    def derives_1(x, y, bettas):\n",
    "        y = y.tolist()\n",
    "        x = x.iloc[i]\n",
    "        return -2 * (y - np.dot(x, bettas[1:]) - bettas[0])\n",
    "    def derives_2(x, y, bettas):\n",
    "        print(y)\n",
    "        x_val = x.iloc[i]\n",
    "        return -2 * x_val[0] * (y - np.dot(x, bettas[1:]) - bettas[0])\n",
    "    def derives_3(x, y, bettas):\n",
    "        return -2 * x[1] * (y - np.dot(x, bettas[1:]) - bettas[0])\n",
    "    def derives_4(x, y, bettas):\n",
    "        return -2 * x[2] * (y - np.dot(x, bettas[1:]) - bettas[0])\n",
    "    def derives_5(x, y, bettas):\n",
    "        return -2 * x[3] * (y - np.dot(x, bettas[1:]) - bettas[0])\n",
    "    \n",
    "    lin = MyLinearRegression(cost_function, [derives_1, derives_2, derives_3, derives_4, derives_5])\n",
    "    #shuffle\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    #separation\n",
    "    x, y = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']], df['mpg']\n",
    "    msk = (int)(len(x) * 0.7)\n",
    "    print(len(y))\n",
    "    print(len(x))\n",
    "\n",
    "    x_train = x.iloc[0:msk]\n",
    "    y_train = y.iloc[0:msk]\n",
    "    x_test = x.iloc[msk:-1]\n",
    "    y_test = y.iloc[msk:-1]\n",
    "    \n",
    "    lin.fit(x_train, y_train)\n",
    "    predicted = lin.predict(x_test)\n",
    "    mse = 0\n",
    "    for i in range(len(predicted)):\n",
    "        mse += (predicted[i] - y_test[i]) ** 2 \n",
    "    mse /= len(predicted)\n",
    "    print(mse)\n",
    "    \n",
    "    #k_fold_cv(dataset, k, lin, 'regression', ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration'])\n",
    "lin_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([10.37522832]), array([9.28884745]), array([12.57132636]), array([9.34767029]), array([15.63091383])] [11.44279725]\n"
     ]
    }
   ],
   "source": [
    "df_logistic = pd.read_csv('datasets/iris.csv')\n",
    "\n",
    "df_linear = pd.read_csv('datasets/mpg.csv')\n",
    "\n",
    "df_linear = clean_dataset(df_linear, 'horsepower')\n",
    "df_linear.drop(['name'],axis=1, inplace=True)\n",
    "\n",
    "#print(df)\n",
    "regr = linear_model.LogisticRegression()\n",
    "lin = linear_model.LinearRegression()\n",
    "mses, mmse = k_fold_cv(df_linear, 5, lin, 'regression', ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin'])\n",
    "print(mses, mmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 126, 330, 336, 354, 374]\n",
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower      float64\n",
      "weight            int64\n",
      "acceleration    float64\n",
      "model_year        int64\n",
      "origin            int64\n",
      "name             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_linear = pd.read_csv('datasets/mpg.csv')\n",
    "df_linear = clean_dataset(df_linear, 'horsepower')\n",
    "df_linear['horsepower'] = df_linear.horsepower.astype(float)\n",
    "print(df_linear.dtypes)\n",
    "# df_linear = clean_dataset(df_linear, 'horsepower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214161</td>\n",
       "      <td>0.745174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659387</td>\n",
       "      <td>0.945610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "2  0.214161  0.745174\n",
       "3  0.659387  0.945610"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random((6, 2)), columns=list('AB'))\n",
    "df.iloc[[2, 3], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
