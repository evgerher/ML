{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib import markers\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds indices of closest clusters to be merged on next iteration\n",
    "# clusters_matrix - clusters matrix\n",
    "# distance_col, cluster_col - ids of columns keeping min distance and closest cluster id\n",
    "# returns cluster indices and distance between them\n",
    "def find_clusters_to_merge(clusters_matrix, distance_col, cluster_col):\n",
    "    min_index = np.argmin(clusters_matrix[:, distance_col])\n",
    "    min_dist = clusters_matrix[min_index, distance_col]\n",
    "    target = clusters_matrix[min_index, cluster_col]\n",
    "    \n",
    "#     print(\"DEBUG FROM FIND CLUSTERS\")\n",
    "#     print(min_index, target, min_dist)\n",
    "\n",
    "    \n",
    "    return min_index, target, min_dist\n",
    "\n",
    "def get_members(sets, c1, c2):\n",
    "    sets[c1] = list(sets[c1] + sets[c2])\n",
    "    sets[c2] = sets[c1]\n",
    "    return sets[c1]\n",
    "\n",
    "def get_participants(X_data):\n",
    "    d = {}\n",
    "    uniq = np.unique(X_data[:, -1])\n",
    "    for v in uniq:\n",
    "        i = int(v)\n",
    "        d[i] = [i]\n",
    "    return d\n",
    "\n",
    "def update_clusters(X_matrix, clusters_matrix, members, cluster_id, val=np.inf):\n",
    "    for index in members:\n",
    "        for subindex in members:\n",
    "            clusters_matrix[index, subindex] = val\n",
    "            clusters_matrix[subindex, index] = val\n",
    "\n",
    "        X_matrix[index, -1] = cluster_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performs merge of clusters with indices c1_index, c2_index\n",
    "# updates single-linkage distances in clusters_matrix\n",
    "# updates cluster membership column in X_matrix\n",
    "# c1_index, c2_index - indices of clusters to be merged\n",
    "# X_matrix - data + cluster membership column\n",
    "# distance_col, cluster_col - ids of columns keeping min distance and closest cluster id\n",
    "# distances_matrix - initial pairwise distances matrix, good implementation doesn't need it in this method\n",
    "def single_link_merge(c1_index, c2_index, X_matrix, clusters_matrix, distance_col, cluster_col, distances_matrix, sets):\n",
    "    c1 = int(c1_index)\n",
    "    c2 = int(c2_index)\n",
    "    \n",
    "    members_c1 = get_members(sets, c1, c2)\n",
    "    update_clusters(X_matrix, clusters_matrix, members_c1, c1, val=np.inf)\n",
    "\n",
    "#     print(\"c1 = {} c2 = {}, merge distance = {}\".format(c1, c2, clusters_matrix[c1, c2]))\n",
    "#     print(members_c1)\n",
    "    \n",
    "    \n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        if cluster_id not in members_c1:\n",
    "            v1 = clusters_matrix[c1, cluster_id]\n",
    "            v2 = clusters_matrix[c2, cluster_id]\n",
    "            min_dist = min(v1, v2)\n",
    "            clusters_matrix[cluster_id, c1] = min_dist\n",
    "            clusters_matrix[c1, cluster_id] = min_dist\n",
    "            clusters_matrix[cluster_id, c2] = np.inf\n",
    "            clusters_matrix[c2, cluster_id] = np.inf\n",
    "        \n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        min_index = np.argmin(clusters_matrix[cluster_id, :distance_col])\n",
    "        min_dist = clusters_matrix[cluster_id, min_index]\n",
    "        clusters_matrix[cluster_id, distance_col] = min_dist\n",
    "        clusters_matrix[cluster_id, cluster_col] = min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performs merge of clusters with indices c1_index, c2_index\n",
    "# updates complete-linkage distances in clusters_matrix\n",
    "# updates cluster membership column in X_matrix\n",
    "# c1_index, c2_index - indices of clusters to be merged\n",
    "# X_matrix - data + cluster membership column\n",
    "# distance_col, cluster_col - ids of columns keeping min distance and closest cluster id\n",
    "# distances_matrix - initial pairwise distances matrix, good implementation doesn't need it in this method\n",
    "def complete_link_merge(c1_index, c2_index, X_matrix, clusters_matrix, distance_col, cluster_col, distances_matrix, sets):\n",
    "    c1 = int(c1_index)\n",
    "    c2 = int(c2_index)\n",
    "    \n",
    "#     print(\"c1 = {} c2 = {}, merge distance = {}\".format(c1, c2, clusters_matrix[c1, c2]))\n",
    "#     print(\"Merging l1 = {} and l2 = {}\".format(sets[c1], sets[c2]))\n",
    "\n",
    "\n",
    "    members_c1 = get_members(sets, c1, c2)\n",
    "#     print(\"Result merge = {}\".format(members_c1))\n",
    "\n",
    "    update_clusters(X_matrix, clusters_matrix, members_c1, c1, val=-1)\n",
    "    \n",
    "    \n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        if cluster_id not in members_c1:\n",
    "            v1 = clusters_matrix[c1, cluster_id]\n",
    "            v2 = clusters_matrix[c2, cluster_id]\n",
    "            max_dist = max(v1, v2)\n",
    "            clusters_matrix[cluster_id, c1] = max_dist\n",
    "            clusters_matrix[c1, cluster_id] = max_dist\n",
    "            clusters_matrix[cluster_id, c2] = np.inf\n",
    "            clusters_matrix[c2, cluster_id] = np.inf\n",
    "        \n",
    "        \n",
    "    update_clusters(X_matrix, clusters_matrix, members_c1, c1, val=np.inf)\n",
    "\n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        min_index = np.argmin(clusters_matrix[cluster_id, :distance_col])\n",
    "        min_dist = clusters_matrix[cluster_id, min_index]\n",
    "        clusters_matrix[cluster_id, distance_col] = min_dist\n",
    "        clusters_matrix[cluster_id, cluster_col] = min_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performs merge of clusters with indices c1_index, c2_index\n",
    "# updates average-linkage distances in clusters_matrix\n",
    "# updates cluster membership column in X_matrix\n",
    "# c1_index, c2_index - indices of clusters to be merged\n",
    "# X_matrix - data + cluster membership column\n",
    "# distance_col, cluster_col - ids of columns keeping min distance and closest cluster id\n",
    "# distances_matrix - initial pairwise distances matrix, use it for this method\n",
    "def average_link_merge(c1_index, c2_index, X_matrix, clusters_matrix, distance_col, cluster_col, distances_matrix, sets):\n",
    "    c1 = int(c1_index)\n",
    "    c2 = int(c2_index)\n",
    "    \n",
    "#     print(\"c1 = {} c2 = {}, merge distance = {}\".format(c1, c2, clusters_matrix[c1, c2]))\n",
    "#     print(\"Merging l1 = {} and l2 = {}\".format(sets[c1], sets[c2]))\n",
    "\n",
    "\n",
    "    members_c1 = get_members(sets, c1, c2)\n",
    "#     print(\"Result merge = {}\".format(members_c1))\n",
    "\n",
    "    update_clusters(X_matrix, clusters_matrix, members_c1, c1, val=np.inf)\n",
    "    \n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        if cluster_id not in members_c1:\n",
    "            v1 = clusters_matrix[c1, cluster_id]\n",
    "            v2 = clusters_matrix[c2, cluster_id]\n",
    "            dist = (v1 + v2) / 2\n",
    "            clusters_matrix[cluster_id, c1] = dist\n",
    "            clusters_matrix[c1, cluster_id] = dist\n",
    "            clusters_matrix[cluster_id, c2] = np.inf\n",
    "            clusters_matrix[c2, cluster_id] = np.inf\n",
    "\n",
    "    for cluster_id in range(X_matrix.shape[0]):\n",
    "        min_index = np.argmin(clusters_matrix[cluster_id, :distance_col])\n",
    "        min_dist = clusters_matrix[cluster_id, min_index]\n",
    "        clusters_matrix[cluster_id, distance_col] = min_dist\n",
    "        clusters_matrix[cluster_id, cluster_col] = min_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the function which performs bottom-up (agglomerative) clustering\n",
    "# merge_func - one of the three merge functions above, each with different linkage function\n",
    "# X_matrix - data itself\n",
    "# threshold - maximum merge distance, we stop merging if we reached it. if None, merge until there only is one cluster\n",
    "def bottom_up_clustering(merge_func, X_matrix, distances_matrix, threshold=None):\n",
    "    num_points = X_matrix.shape[0]\n",
    "\n",
    "    # take dataset, add and initialize column for cluster membership\n",
    "    X_data = np.c_[X_matrix, np.arange(0, num_points, 1)]\n",
    "\n",
    "    # create clusters matrix, initially consisting of all points and pairwise distances\n",
    "    # with last columns being distance to closest cluster and id of that cluster\n",
    "    clusters = np.c_[distances_matrix, np.zeros((num_points, 2))]\n",
    "\n",
    "    # ids of added columns - column with minimal distances, column with closest cluster ids\n",
    "    dist_col_id = num_points\n",
    "    clust_col_id = num_points + 1\n",
    "\n",
    "    # calculate closest clusters and corresponding distances for each cluster\n",
    "    clusters[:, clust_col_id] = np.argmin(clusters[:, :num_points], axis=1)\n",
    "    clusters[:, dist_col_id] = np.amin(clusters[:, :num_points], axis=1)\n",
    "\n",
    "    # array for keeping distances between clusters that we are merging\n",
    "    merge_distances = np.zeros(num_points - 1)\n",
    "    \n",
    "    # My variable\n",
    "    sets = get_participants(X_data)\n",
    "    # main loop. at each step we are identifying and merging two closest clusters (wrt linkage function)\n",
    "    for i in range(0, num_points - 1):\n",
    "        c1_id, c2_id, distance = find_clusters_to_merge(clusters, dist_col_id, clust_col_id)\n",
    "        # if threshold is set, we don't merge any further if we reached the desired max distance for merging\n",
    "        if threshold is not None and distance > threshold:\n",
    "            break\n",
    "        merge_distances[i] = distance\n",
    "        merge_func(c1_id, c2_id, X_data, clusters, dist_col_id, clust_col_id, distances_matrix, sets)\n",
    "#         break\n",
    "        # uncomment when testing\n",
    "#         print(\"Merging clusters #\", c1_id, c2_id)\n",
    "#         if i%30 == 0:\n",
    "#             for k, (marker, color) in zip(range(num_points), itertools.product(markerss, colormap)):\n",
    "#                 plt.scatter(X_data[X_data[:, 2] == k, 0], X_data[X_data[:, 2] == k, 1], color=color, marker=marker, label=k)\n",
    "#             plt.show()\n",
    "    \n",
    "    # todo use the plot below to find the optimal threshold to stop merging clusters\n",
    "    plt.plot(np.arange(0, num_points - 1, 1), merge_distances[:num_points - 1])\n",
    "    plt.title(\"Merge distances over iterations\")\n",
    "    plt.xlabel(\"Iteration #\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "\n",
    "    for k, (marker, color) in zip(range(num_points), itertools.product(markerss, colormap)):\n",
    "        plt.scatter(X_data[X_data[:, 2] == k, 0], X_data[X_data[:, 2] == k, 1], color=color, marker=marker)\n",
    "    plt.title('Clusters of customers')\n",
    "    plt.xlabel('Annual Income (k$)')\n",
    "    plt.ylabel('Spending Score (1-100)')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "dataset = pd.read_csv('datasets/Mall_Customers.csv')\n",
    "X = dataset.iloc[:, [3, 4]].values\n",
    "\n",
    "# creating and populating matrix for storing pairwise distances\n",
    "# diagonal elements are filled with np.inf to ease further processing\n",
    "distances = squareform(pdist(X, metric='euclidean'))\n",
    "np.fill_diagonal(distances, np.inf)\n",
    "\n",
    "# seting up colors and marker types to use for plotting\n",
    "markerss = markers.MarkerStyle.markers\n",
    "colormap = plt.cm.Dark2.colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# performing bottom-up clustering with three different linkage functions\n",
    "# todo set your own thresholds for each method.\n",
    "# todo find thresholds by looking at plot titled \"Merge distances over iterations\" when threshold is set to None\n",
    "bottom_up_clustering(single_link_merge, X, distances, threshold=10)\n",
    "bottom_up_clustering(complete_link_merge, X, distances, threshold=10)\n",
    "bottom_up_clustering(average_link_merge, X, distances, threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
